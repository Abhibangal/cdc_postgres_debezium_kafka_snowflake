# ğŸ§© Containerized CDC Ingestion Pipeline (Postgres â†’ Debezium â†’ Kafka â†’ Snowflake)

This repository contains a **containerized Change Data Capture (CDC) pipeline** built using **Docker**, **Debezium**, **Kafka**, and **Snowflake**.  
It captures **log-based changes from PostgreSQLâ€™s Write-Ahead Logs (WAL)**, streams them through Kafka, and ingests them into Snowflake â€” where a **dynamic SCD Type 2 table** is maintained.

---

## ğŸ“ Project Overview

### Components:
- **Postgres** â€“ Source database configured with WAL-based CDC (Write-Ahead Logs)
- **Debezium** â€“ Captures database change events from Postgres WAL logs
- **Kafka & Kafka Connect** â€“ Handles message streaming and connector management
- **Snowflake Connector** â€“ Consumes Kafka topics and writes to Snowflake
- **Docker Compose** â€“ Orchestrates and runs all containerized services

---

## âš™ï¸ Folder Structure

```
â”œâ”€â”€ connectors/
â”‚   â””â”€â”€ snowflake/                         # Contains all Snowflake Kafka connector JARs and related files
â”‚
â”œâ”€â”€ init_connectors/
â”‚   â”œâ”€â”€ postgres-connector.json            # Debezium connector configuration for Postgres (WAL-based CDC)
â”‚   â”œâ”€â”€ snowflake-connector.json           # Kafka connector configuration for Snowflake
â”‚   â””â”€â”€ register-connectors.sh             # Script to register both connectors
â”‚
â”œâ”€â”€ postgres/
â”‚   â”œâ”€â”€ 01_table_creation.sql              # Postgres DDL scripts for table setup
â”‚   â”œâ”€â”€ 02_admin_queries.sql               # Admin-level Postgres queries
â”‚   â””â”€â”€ 03_insert_into_user_query.sql      # Sample insert statements for CDC testing
â”‚
â”œâ”€â”€ snowflake/
â”‚   â”œâ”€â”€ 01_admin_queries_snowflake.sql     # Snowflake admin and setup queries
â”‚   â””â”€â”€ 02_SCD_2_Dynamic_table_queries.sql # Dynamic table and SCD Type 2 logic queries
â”‚
â”œâ”€â”€ docker-compose.yaml                    # Docker setup for Postgres, Kafka, Debezium, and connectors
â”œâ”€â”€ RUN_GUIDE.txt                          # Step-by-step guide to run and validate the pipeline
â”œâ”€â”€ debugging_command.txt                  # Commands for troubleshooting and debugging
â””â”€â”€ README.md                              # Project documentation (this file)
```

---

## ğŸš€ Setup Instructions

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd <your-repo-name>
```

### 2. Start the Docker Containers
Spin up all services using Docker Compose:
```bash
docker compose up -d
```
This will start Postgres, Kafka, Zookeeper, and Debezium Connect containers.

---

## ğŸ”— Connector Setup

After the containers are running, register the connectors by executing the script inside the **init_connectors** folder:

```bash
bash init_connectors/register-connectors.sh
```

This registers:
- **Postgres connector** â†’ Reads WAL logs for CDC
- **Snowflake connector** â†’ Writes CDC data into Snowflake

You can verify connector registration and status via:
```bash
docker logs connect
```

---

## â„ï¸ Snowflake Configuration

In Snowflake:
- Create the necessary database, schema, and stage using **`01_admin_queries_snowflake.sql`**  
- Use **`02_SCD_2_Dynamic_table_queries.sql`** to set up the **dynamic table** for implementing **Slowly Changing Dimension (SCD) Type 2**
- The data flows from the **raw_use_log** table (ingested via Kafka) to the **SCD2 dynamic table**

---

## ğŸ§  Debugging

If you face issues during setup or runtime, refer to:
```
debugging_command.txt
```
This file contains helpful Docker, Kafka, and connector debugging commands.

---

## ğŸ§¾ Reference Files

- **`RUN_GUIDE.txt`** â€“ Quick guide for running and validating the pipeline  
- **`debugging_command.txt`** â€“ Useful commands for troubleshooting  
- **`docker-compose.yaml`** â€“ Service orchestration for all CDC components  
- **`postgres`** folder â€“ All Postgres SQL setup scripts  
- **`snowflake`** folder â€“ All Snowflake setup and SCD2 logic scripts  
- **`init_connectors`** â€“ JSON configs and registration scripts for connectors

---

## âœ… Data Flow Summary

```
Postgres (WAL Logs)
     â”‚
     â–¼
 Debezium (Log-based CDC Capture)
     â”‚
     â–¼
 Kafka Topics
     â”‚
     â–¼
 Snowflake (Ingestion via Connector)
     â”‚
     â–¼
 Dynamic SCD2 Table
```

---

## ğŸ§° Tools & Technologies

- **Docker / Docker Compose**
- **PostgreSQL (WAL-based CDC)**
- **Kafka / Zookeeper**
- **Debezium**
- **Snowflake**
- **Snowflake Kafka Connector**

---

## ğŸ“œ Notes

This setup demonstrates an **end-to-end, log-based CDC pipeline** using PostgreSQLâ€™s **Write-Ahead Logs (WAL)** for data capture.  
It ensures near real-time synchronization from Postgres to Snowflake with **SCD Type 2** handling for historical data tracking.  

Refer to the included guide files for detailed setup, execution, and debugging steps.
